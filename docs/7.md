---
title: At your service
category:
---

Since leaving the culinary world, in albeit a brief stint, I’ve spent nearly the entirety of my career supporting what everyone refers to as IT (laptop don’t boot) to supporting, leading, and evangelizing digital products. This world was wacky before OpenAI, Silcon Valley is not real - but it’s a viciously accurate caricature. 

The introduction of silicon intelligence, this time in a very specific set of neural-like approaches, permeated the zeitgeist with a furor that has rarely been seen. The equal moment in my recent memory is the classic iPhone moment, but even that set the barrier to entry at a rather high price point. 

Currently, we are paying the price of this in the form of our data, our feedback, our interactions, for the astronomical costs that they take to build. 

As predicted by many, the plethora of ‘proofs of concept, early alphas, invite-only, labs initiatives’ - they all give away the certain truth: they are underbaked. 

The lowest of the hanging fruit comes in the form of summarization buttons and AOL ‘95 chat bots. The interface isn’t clever, nor is it novel. The application of these tools, as one would expect, focused on those things that the Large Language Models could do predictably. Chat was fraught with potential issues, as it was only too recently Microsoft trained on twitter, whose output amplified immediately those parts of twitter that remain a concerted core of its base.

As these models improved, and most importantly the post-covid-world-community saw the introduction of these tools make their way to ‘open’ standards relatively quickly - there was a plethora of frameworks, experimentation, and shared knowledge that erupted through the well-worn network that Github controlls. These improvements ranged from to new training approaches, models, sample data - and a whole separate thread of development focused on plugging this ‘intelligence’ into the world of modern computing. This includes the work in new ‘modalities’ (sound / video), as well as the interfaces with computing platforms and languages so that these models may begin to take ‘useful’ actions. 

- As an aside, it is useful to say - GPT-4o is not a brain. Mixture of Experts is not a brain. Nor are any of these things in same ballpark as a human, and all of the necessary parts. Not subjecting a judgement of better or worse, that’s for the fates to decide - but just to say that the process of a ‘neural’ network is simply a game of mimicry by silicon of the best that carbon has to offer for the moment when it comes to “intelligence”. 

But the mere fact is, for a plethora of reasons, but notably silicon’s proximit to copper rather to carbon means it has a set of ‘super-human’ aspects that cannot be ignored:
1. These things are not what you would call a human intelligence, but they’re mimicking the underpinnings of how they work.
2. These things will get “more intelligent”.
4. The arguements over what is “intelligent” are far from over. 
4. The “less complex” a problem is, the more likely this intelligence becomes useful. 
5. When the problem is simple, and speed is a factor - the LLM wins. Much like in a human brain, the interplay between multiple aspects of ‘intelligence’ typically make themselves more useful when solving a problem over a singular ‘intelligence’

As the general applicability of the base models, from providers focusing on differeing sets of customer applications - from recipe ideas to writing rust functions - has seen some recent plateaus in ‘usefulness increases’ with each new iteration of models released. This, and the inherent power imbalance in Platform (OpenAI) and App (ChatGPT) have when working with “integrators” and “partners -  has caused the market to begin focus on the ‘interface’ that a user interacts with. 

Some notable examples are of course CoPilot, and its recent developments with Workspaces - but a top tier entrant is the IDE from Cursor. While stepping on the shoulder of the VS COde giants (a documentary of its slow takeover needs to be made), but reinventing the way that the ‘intelligence’ of the ‘copilot’ by interjecting changes into the code, bouncing back and forth between chat and code effortlessly. 

In addition, they force the issue of multiple models through a deep connection (and stupendous output) with Anthropic. 

I’d like to call this low hanging fruit for the moment, if we were take a moment and look above the parapet of where this kind of technology can go. I’m writing this today, before many of these arguements are fully baked, because I believe that the time horizon of these things becoming much more powerful (still less than AGI though) is very very soon. 

Thinking of the problem of interface: the sheer volume  of integration points where ‘intelligence’ can add value today represents a serious shift in previously ‘well-worn’ patterns and processes of human behaviour. 

An example of this, with its corresponding rippling of downstream ramifications, is Google’s stranglehold on the Advertising market, due to the sheer reliance on an unchanging process for spreading knowledge: the search engine. 

What happens when that muscle “memory” is wiped away - with the introduction of ‘good enough’ knowledge retrievers in LLM (chat). In fact if you think about it, ChatGPT, and the chat approach in general, provides 1 less ‘click per knowledge shared’ (search -> click link vs. hit enter to chat), and upended the whole ecosystem. 

The massive proliferation of ChatGPT specifically, and it’s minimal-come-last-minute approach to interface design. If my memory is correct, Altman said he was shocked no one stepped into the space. Huge mistake for anyone who looked at it and bailed. 

One of the indicators of the sheer power of this neural-like approach to software is, when interjected into the back of an evolved* AOL Instant Messenger interface, the entire world adopts it. Nearly instantly if you look at the rate of change when monumental shifts are introduced. We are on a jet ski lapping a historical titanic. 

The thing is - this kind of neural-like approach does not rely on chat as its means of conveyance, and the early introduction of linting/filtering of output from certain models allowed to constrain the LLM to a certain mode/interaction model with its host. 

Let’s take a problem plauging the early 20th century, that of onboarding / adapting to new pieces of SaaS software. 

THe perrenial problem, and one that is like bull fighting on top of quicksand - as your product enters new markets, experiences new competition, new changes in behaviour - you find yourself chasing the dream of a user who can simply self serve. 


Like many modes of communication in the 20th centure (and previous), the 21st Century adopted many of the old tropes to meet the widest addressable user’s need (which naturally included both centuries). A simple example: the “Save Icon”. 

Poll the planet today  - how many of us have actually seen a floppy disk? 

It becomes a literal icon. 

Another is the manual. 

THe manual, in its manifestation as a ream of technical docs, guides, literal white papers. 

This is a tried and true method of communication, thanks Mr. Gutenberg , but it is in no way the only way to get someone from discovering a new product, and getting ‘hooked’ on using ‘just enough’ features to justify purchase. 

This is a subtle art, especially when you consider that you’re playing a game of postcards when interacting with your customer. In the world SaaS, you live and die by leaving the right breadcrumbs, no matter the faceless user, to keep everyone in business. 

On top of this, you rarely have more than your written word, and your choice(s) of interface. How the thing works, how it delivers - this is core - but how a user adapts to the software, or the software adapts to the user, is where the sweet spot of significant growth is found. 


Let’s say it’s the 21st century, let’s say that the power of artificial intelligence is bestowed upon us - how would you approach this problem? 
 
There are still people alive who got their internet minutes from a CD.

Chat is still going to be a thing. In this century, the number of people who grew up communicating digitally chose to hurl text at each other. From my own timeline, this was nearly-exlusively because it was the first communication, in a cheaply built house with walls of paper, that could be had without audit from the family. 

Now imagine for just a second that you could have this moment at a much less significant scale than that of an MIT scholar’s problem, solved by Jon Nash. What it if was something no more clever than dropping one’s car keys in front of their eyes at the time that the _REALLY_ needed it. Bonus points if you can find the keys before one even knows that they need it!

Often, as any product manager will tell you, the level of ‘problem’ here is a lot more simple than that of a ground-breaking mathematics formula. Often what we’re talking about is the right shade of blue on a roudned, not square, button in HTML. 

The simplicity here means that it is likely that a plethora of methods can be employed to ensure that ANY user, who encounters a new product, experience, service - anything that can be ‘costed’ in terms of ‘value it creates’, and can be purchased - should be instantly sheparded to the ‘promised land’ of satisfaction. 

Mostly, in the industry as it stands, the interface for this ‘intelligence’ is that of the chat. Well before the introduction of the known-and-standardized modle of ‘chatbots’, the world of AOL was one shrowded in mystery. 

Imagine entering the world of comedic timing in text-based communication - was that ironic pause simply ironic, or did your parent pick up the phone while you were trying to chat. That’s exactly what you’re exposing GPT to right now... 

Back to the subject at hand - imagine for a second, it’s 1995, you are on your computer ALL THE TIME, and all of a sudden, you have a friend who knows EXACTLY what you want to do next. 

Like, on everything. How would your world be different? 

Let’s do Adam Smith or Karl Marx - what would it mean if you were the only person in your tribe, in your village, who had such a gift? 

Would you be labelled the village idiot, the mayor, the demigod? 

Or would it even matter? Conversely, imagine for a second that EVERYONE got this power. 

The thing about the chat interface, is that from the outset there’s a wealth of assumptions that are pre-baked upon arrival - 
1. You are talking to something trying to pass the turing test
2. If they’re not passing the turing test, they identify themselves as algorithmic and engage on the pre-defined topic of choice

This is but a trick hidden in this interface, as the whole of a chat interface (including often such standards as HTML, Javascript, and every once in a while a C variant - all of these can be incluenced by the power of LLMs. People log in to ChatGPT, they interact with the only bit of the platform that an LLM is 

- Another aside, there’s a unique property of these Large Language Models that makes this problem interesting. It has to do with how you ‘build’ these things. It’s many parts - including interface, storage, compute, but most importantly it’s how the thing is “trained” on source material. In the case of LLMs, this data catalog is astronomically large, and thus ‘training sessions’ take a lot of time and a whole lot of money. In principle, this means that almost immediately as you start training one of these things, they are going to be out of date with their knowledge. - 

Access to data about the here and now is often more important than being able to call up with impeccible precision the names of very King between 1788 and January 12th 1983. Because of this, the evolution of many LLMs is to adopt implentation approaches that combine a general knowledge with a source of relevant data. That relevance can simply be one of recency, but also this is the method you would use to ‘focus’ an LLM on a subject. 

One very early realisation that enthusiasts/explorers in this space discovered was something the AI OGs had already known: the similarities between code and language make them equally viable as something this ‘intelligence’ can be useful when interacting with. This includes everything from inference and understanding, to generating and automating. 

The ability to personalise and augment the underlying infrastructure software is delivered in, on the fly, is at within grasp here. 

The rule of similarity between two different written forms of ‘information’, that of code and language, also have their corresponding compliments in the audible and visual. The methods of training, in a ‘neural’ approach, enables new methods for retrieval and generation in this non-written domain. There’s so much untapped potential here, where we might finally see rid of the typewriter’s influence on spreading knowledge. 

One thing seems to continue to be true, which applies across the board: the technology/service that aids in the curiosity of human beings find their successes one way or another. People signing up to a new SaaS app for the first time are explorers: it is uncharted territory. This new world presents all sorts of challenges, all sorts of potential and opportunity. Introducing intelligence in areas that aid in this general curiosity which defines human beings yeilds near-instant results. 

The evolution of human brains, including aspects like ability to function, remember, addiction to dopamine, etc. etc. - these are all about to change...this rapid introduction of information to a brain is about to really disrupt what was already a chaotic development. 

Adapting to these changes as they erupt and crash is the only way to stay afloat. This is about to be a really wild ride, certainly in the world of creating software, lest the remained of the human experience. 